{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 data analysis notebook \n",
    "#### @kevinofsydney\n",
    "\n",
    "Notes:\n",
    "- The 'KeyError' is because the name of the column gets consumed when it is turned into an index \n",
    "- df.describe() is useful\n",
    "- oddsportal.com\n",
    "- race_df['name'].unique()\n",
    "- http://www.f1-predictor.com/category/data-science/\n",
    "- https://www.f1hotornot.com/ - this is a very good form rating, and could be used to also indicate whether a driver is expected to overperform or underperform their average\n",
    "\n",
    "\"How should we apply cross-validation to data that are time-ordered (like F1 results)? The basic idea remains the same but instead of splitting the training data into 3 random folds, we break it in a way that the validation data always refer to a later period compared to the training data.\n",
    "\n",
    "\"Hereâ€™s how your CV would work: you train the model on the first 20 races and you make predictions for the next 10 ones. You calculate the relevant metrics. Then, you train the model on the first 30 races (or the races 11-30, this is a choice you have to take) and predict on the next 10. You keep doing this for the next 2 folds. Finally, you calculate the average performance.\"\n",
    "\n",
    "\n",
    "### To do list\n",
    "- Automate adding the column labels\n",
    "- Calculate the average race result for each driver\n",
    "- Create a working prototype to predict qualifier results\n",
    "- Create a working prototype to predict race results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "OUTPUT = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raceId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>constructorId</th>\n",
       "      <th>grid</th>\n",
       "      <th>positionOrder</th>\n",
       "      <th>circuitId</th>\n",
       "      <th>raceresult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>900</td>\n",
       "      <td>3</td>\n",
       "      <td>131</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>900</td>\n",
       "      <td>825</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>900</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>900</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>900</td>\n",
       "      <td>822</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   raceId  driverId  constructorId  grid  positionOrder  circuitId  raceresult\n",
       "0     900         3            131     3              1          1           1\n",
       "1     900       825              1     4              2          1           1\n",
       "2     900        18              1    10              3          1           1\n",
       "3     900         4              6     5              4          1           2\n",
       "4     900       822              3    15              5          1           2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the files\n",
    "cir_df = pd.read_csv('circuits_l.csv')\n",
    "conresult_df = pd.read_csv('constructor_results_l.csv')\n",
    "constanding_df = pd.read_csv('constructor_standings_l.csv')\n",
    "con_df = pd.read_csv('constructors_l.csv')\n",
    "driver_df = pd.read_csv('driver_l.csv')\n",
    "laptime_df = pd.read_csv('lap_times_l.csv')\n",
    "quali_df = pd.read_csv('qualifying_l.csv')\n",
    "race_df = pd.read_csv('races_l.csv')\n",
    "result_df = pd.read_csv('results_l.csv')\n",
    "status_df = pd.read_csv('status_l.csv')\n",
    "\n",
    "# Set the correct indices \n",
    "race_df['date'] = pd.to_datetime(race_df['date'], dayfirst=True)\n",
    "\n",
    "# driver_df.set_index('driverId', inplace=True)\n",
    "quali_df.set_index('qualifyId', inplace=True)\n",
    "laptime_df.set_index('raceId', inplace=True)\n",
    "race_df.set_index('date', inplace=True)\n",
    "result_df.set_index('resultId', inplace=True)\n",
    "\n",
    "# race_df.sort_values('raceId', inplace=True)\n",
    "race_df.sort_index(inplace=True)\n",
    "\n",
    "# Remove unnecessary columns, or columns I still need to implement processing for\n",
    "result_df = result_df.drop('number', axis=1)\n",
    "\n",
    "resultsm_df = result_df[['raceId', 'driverId', 'constructorId', 'grid', 'positionOrder']]\n",
    "\n",
    "def label_points(row):\n",
    "    if row['positionOrder'] <= 3:\n",
    "        return 1 #'top3'\n",
    "    elif row['positionOrder'] > 3 and row['positionOrder'] <= 6:\n",
    "        return 2 # 'top6'\n",
    "    elif row['positionOrder'] > 6 and row['positionOrder'] <= 10:\n",
    "        return 3 #'top10'\n",
    "    else:\n",
    "        return 4 #'no_points'\n",
    "\n",
    "resultsm_df = resultsm_df.merge(race_df[['raceId', 'circuitId']], how='left', on=['raceId'])\n",
    "resultsm_df['raceresult'] = resultsm_df.apply(label_points, axis=1)\n",
    "resultsm_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the constructors to strings, and then applying OHE. \n",
    "# Converting constructor names to strings allows for the columns to be named informatively\n",
    "\n",
    "def name_constructors(row):\n",
    "    if row['constructorId'] == 1:\n",
    "        return 'MCL'\n",
    "    elif row['constructorId'] == 3:\n",
    "        return 'WIL'\n",
    "    elif row['constructorId'] == 4:\n",
    "        return 'REN'\n",
    "    elif row['constructorId'] == 5:\n",
    "        return 'TOR'\n",
    "    elif row['constructorId'] == 6:\n",
    "        return 'FER'\n",
    "    elif row['constructorId'] == 9:\n",
    "        return 'RBR'\n",
    "    elif row['constructorId'] == 10:\n",
    "        return 'RCP'\n",
    "    elif row['constructorId'] == 15:\n",
    "        return 'SAU'\n",
    "    elif row['constructorId'] == 51:\n",
    "        return 'ALF'\n",
    "    elif row['constructorId'] == 131:\n",
    "        return 'MER'\n",
    "    elif row['constructorId'] == 206:\n",
    "        return 'RUS'\n",
    "    elif row['constructorId'] == 207:\n",
    "        return 'CAT'\n",
    "    elif row['constructorId'] == 208:\n",
    "        return 'LOT'\n",
    "    elif row['constructorId'] == 209:\n",
    "        return 'MAN'\n",
    "    elif row['constructorId'] == 210:\n",
    "        return 'HAA'\n",
    "    elif row['constructorId'] == 211:\n",
    "        return 'RCP'\n",
    "    \n",
    "# Converting the constructors to Categorical data type\n",
    "resultsm_df['cstrIdString'] = resultsm_df.apply(name_constructors, axis=1)\n",
    "resultsm_df['cstrIdString'] = pd.Categorical(resultsm_df['cstrIdString'])\n",
    "\n",
    "# Geting the dummies of the categories\n",
    "cstrStringDummies = pd.get_dummies(resultsm_df['cstrIdString'], prefix='cstr')\n",
    "cstrStringDummies.head(10)\n",
    "\n",
    "# Add the dummy columns back into the main results df \n",
    "resultsm_df = pd.merge(resultsm_df, cstrStringDummies, left_index=True, right_index=True)\n",
    "\n",
    "# Save the constructorIdStrings to put back in after predictions\n",
    "cstrIdStrings = resultsm_df[['cstrIdString']]\n",
    "\n",
    "# Drop the original columns from the testing data so that only the OHE form of the cstr remains\n",
    "if 'cstrIdString' in resultsm_df.columns:\n",
    "    resultsm_df = resultsm_df.drop(columns=['cstrIdString'])\n",
    "\n",
    "if 'constructorId' in resultsm_df.columns: \n",
    "    resultsm_df = resultsm_df.drop(columns=['constructorId'])\n",
    "    \n",
    "# resultsm_df = resultsm_df.drop('raceId', axis=1)\n",
    "# result_df = result_df.drop('number', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raceresult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>577.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.079723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.124485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       raceresult\n",
       "count  577.000000\n",
       "mean     3.079723\n",
       "std      1.124485\n",
       "min      1.000000\n",
       "25%      2.000000\n",
       "50%      4.000000\n",
       "75%      4.000000\n",
       "max      4.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting into training and test sets\n",
    "# data - resultsm_df[['circuitId', 'driverId', 'constructorId', 'grid']]\n",
    "# target - resultsm_df[['raceresult']]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Driver-OHE version\n",
    "data_train, data_test, label_train, label_test = train_test_split(resultsm_df.drop(columns=['raceresult']),\n",
    "                                                                  resultsm_df[['raceresult']],\n",
    "                                                                  test_size=0.25, \n",
    "                                                                  random_state=1)\n",
    "\n",
    "# data_train.describe()\n",
    "# data_test.describe()\n",
    "# label_train.describe()\n",
    "label_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'normalise'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-388771cbff56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mclf_svm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mpred_svm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf_svm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mpred_svm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpred_svm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'svm_preds'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SVM accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_svm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_svm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'normalise'"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "# Accuracy before constructor OHE: 0.6308\n",
    "# Accuracy after constructor OHE: 1.0 ???\n",
    "\n",
    "from sklearn import svm\n",
    "clf_svm = svm.SVC(kernel='linear', C=1).fit(data_train, np.ravel(label_train))\n",
    "pred_svm = clf_svm.predict(data_test)\n",
    "pred_svm = pd.DataFrame(data=pred_svm, columns=['svm_preds'], normalise=True)\n",
    "print(\"SVM accuracy:\", accuracy_score(label_test, pred_svm))\n",
    "x = pd.merge(pred_svm, label_test, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-Bayes accuracy:  0.7660311958405546\n"
     ]
    }
   ],
   "source": [
    "# Naive-Bayes\n",
    "# Accuracy before constructor OHE: 0.6066\n",
    "# Accuracy after constructor OHE\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "clf_nb = gnb.fit(data_train, np.ravel(label_train))\n",
    "pred_nb = clf_nb.predict(data_test)\n",
    "\n",
    "# Print the accuracy score of the model\n",
    "print(\"Naive-Bayes accuracy: \", accuracy_score(label_test, pred_nb, normalize = True))\n",
    "\n",
    "pred_nb = pd.DataFrame(data=pred_nb, columns=['nb_preds'])\n",
    "\n",
    "nb_result = pd.merge(pd.merge(data_test[['raceId', 'driverId', 'grid', 'positionOrder', 'circuitId']], \n",
    "                     cstrIdStrings, left_index=True, right_index=True), pred_nb, left_index=True, right_index=True)\n",
    "\n",
    "if OUTPUT:\n",
    "    nb_result.to_csv('output/OUTPUT_nb_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a driverId via their code\n",
    "code = 'RAI'\n",
    "did = driver_df[ driver_df['code'] == code]['driverId']\n",
    "print(\"INFO: driverID for\", code, \"is:\", int(did))\n",
    "\n",
    "### Return the result for a single driver\n",
    "resultsm_df[resultsm_df['driverId'] == int(did)].head(20)\n",
    "\n",
    "resultsm_df['driverId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merging the quali, driver_details and results dataframes together\n",
    "quali_rdf = quali_df[['raceId', 'driverId', 'q1', 'q2', 'q3']]\n",
    "master = driver_df[['driverId', 'code']].merge(quali_rdf, how='inner', on=['driverId'])\n",
    "master = master.merge(result_df, how='inner', left_on=['raceId', 'driverId'], right_on=['raceId', 'driverId'])\n",
    "# master.sort_values(by=['raceId', 'positionOrder']).head(50)\n",
    "master.head(5)\n",
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replace raceId with circuitId\n",
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(resultsm_df[['raceId','driverId','constructorId','grid','positionOrder','circuitId', 'raceresult']], figsize=(10,10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
